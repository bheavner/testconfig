#####################################
## Configuring StarCluster Plugins ##
#####################################
# Sections starting with "plugin" define a custom python class which perform
# additional configurations to StarCluster's default routines. These plugins
# can be assigned to a cluster template to customize the setup procedure when
# starting a cluster from this template (see the commented PLUGINS setting in
# the 'smallcluster' template above). Below is an example of defining a user
# plugin called 'myplugin':

# [plugin myplugin]
# NOTE: myplugin module must either live in ~/.starcluster/plugins or be
# on your PYTHONPATH
# SETUP_CLASS = myplugin.SetupClass
# extra settings are passed as __init__ arguments to your plugin:
# SOME_PARAM_FOR_MY_PLUGIN = 1
# SOME_OTHER_PARAM = 2

[plugin modInstaller]
setup_class = mypymods.PyModuleInstaller
modules_to_install = mpmath, scikit-learn

[plugin base-tgr]
setup_class=tagger.Tagger
tags=started-by:James A. Eddy, project:ampAD, mydate:[[date]], alias:[[alias]], localuser:[[localuser]]

[plugin dev-tgr]
setup_class=tagger.Tagger
tags=branch:develop

[plugin gpu-web-tgr]
setup_class=tagger.Tagger
tags=project:HD, application:gpu-cluster, node-type:web 

[plugin gpu-master-tgr]
setup_class=tagger.Tagger
tags=project:HD, application:gpu-cluster, node-type: master

[plugin gpu-data-tgr]
setup_class=tagger.Tagger
tags=project:HD, application:gpu-cluster, node-type: data

[plugin gpu-aggregator-tgr]
setup_class=tagger.Tagger
tags=project:HD, application:gpu-cluster, node-type: aggregator

[plugin gpu-server-tgr]
setup_class=tagger.Tagger
tags=project:HD, application:gpu-cluster, node-type: gpu

[plugin vineet-ctc-tgr]
setup_class=tagger.Tagger
tags=project:CTIC, node-type: high-memory

[plugin user-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/user-bootstrap.sh

[plugin data-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/data-bootstrap.sh

[plugin master-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/master-bootstrap.sh

[plugin web-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/web-bootstrap.sh

[plugin root-web-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/root-web-bootstrap.sh
user=root


[plugin gpu-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/gpu-bootstrap.sh

#dev bootstraps

[plugin data-dev-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/data-dev-bootstrap.sh

[plugin master-dev-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/master-dev-bootstrap.sh

[plugin web-dev-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/web-dev-bootstrap.sh

[plugin root-web-dev-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/root-web-dev-bootstrap.sh
user=root

[plugin gpu-dev-bootstrap]
setup_class=s3shell.S3ShellPlugin
s3_file_path=s3://aurea-nebula/aws-meta/working-files/gpu-dev-bootstrap.sh

######################
## Built-in Plugins ##
######################
# The following plugins ship with StarCluster and should work out-of-the-box.
# Uncomment as needed. Don't forget to update your PLUGINS list!
# See http://web.mit.edu/star/cluster/docs/latest/plugins for plugin details.
#
# Use this plugin to install one or more packages on all nodes
[plugin pkginstaller]
SETUP_CLASS = starcluster.plugins.pkginstaller.PackageInstaller
# # list of apt-get installable packages
PACKAGES = python-insighttoolkit3, python-rpy2

[plugin rinstall]
SETUP_CLASS = starcluster.plugins.pkginstaller.PackageInstaller
# # list of apt-get installable packages
PACKAGES = python-rpy2
#
# Use this plugin to create one or more cluster users and download all user ssh
# keys to $HOME/.starcluster/user_keys/<cluster>-<region>.tar.gz
# [plugin createusers]
# SETUP_CLASS = starcluster.plugins.users.CreateUsers
# NUM_USERS = 30
# # you can also comment out NUM_USERS and specify exact usernames, e.g.
# # usernames = linus, tux, larry
# DOWNLOAD_KEYS = True
#
# Use this plugin to configure the Condor queueing system
# [plugin condor]
# SETUP_CLASS = starcluster.plugins.condor.CondorPlugin
#
# The SGE plugin is enabled by default and not strictly required. Only use this
# if you want to tweak advanced settings in which case you should also set
# DISABLE_QUEUE=TRUE in your cluster template. See the plugin doc for more
# details.
# [plugin sge]
# SETUP_CLASS = starcluster.plugins.sge.SGEPlugin
# MASTER_IS_EXEC_HOST = False
#
# The IPCluster plugin configures a parallel IPython cluster with optional
# web notebook support. This allows you to run Python code in parallel with low
# latency message passing via ZeroMQ.
[plugin ipcluster]
SETUP_CLASS = starcluster.plugins.ipcluster.IPCluster
ENABLE_NOTEBOOK = True
#set a password for the notebook for increased security
NOTEBOOK_PASSWD = G3x9jgTqVTtS 
notebook_directory = notebooks
packer=pickle
#
# Use this plugin to create a cluster SSH "dashboard" using tmux. The plugin
# creates a tmux session on the master node that automatically connects to all
# the worker nodes over SSH. Attaching to the session shows a separate window
# for each node and each window is logged into the node via SSH.
# [plugin tmux]
# SETUP_CLASS = starcluster.plugins.tmux.TmuxControlCenter
#
# Use this plugin to change the default MPI implementation on the
# cluster from OpenMPI to MPICH2.
# [plugin mpich2]
# SETUP_CLASS = starcluster.plugins.mpich2.MPICH2Setup
#
# Configure a hadoop cluster. (includes dumbo setup)
[plugin hadoop]
SETUP_CLASS = starcluster.plugins.hadoop.Hadoop
#
# Configure a distributed MySQL Cluster
# [plugin mysqlcluster]
# SETUP_CLASS = starcluster.plugins.mysql.MysqlCluster
# NUM_REPLICAS = 2
# DATA_MEMORY = 80M
# INDEX_MEMORY = 18M
# DUMP_FILE = test.sql
# DUMP_INTERVAL = 60
# DEDICATED_QUERY = True
# NUM_DATA_NODES = 2
#
# Install and setup an Xvfb server on each cluster node
# [plugin xvfb]
# iETUP_CLASS = starcluster.plugins.xvfb.XvfbSetup
